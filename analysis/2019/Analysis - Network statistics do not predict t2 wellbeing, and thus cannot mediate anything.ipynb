{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Configuration\" data-toc-modified-id=\"Configuration-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Configuration</a></span></li><li><span><a href=\"#Import-and-load\" data-toc-modified-id=\"Import-and-load-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Import and load</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FILE = '../data/2019–2020/postprocessed/df_Rcleaned_train.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import and load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(car)\n",
    "library(tidyverse)\n",
    "library(hexbin)\n",
    "library(mice)\n",
    "library(nlme)\n",
    "library(lme4)\n",
    "library(lmerTest)\n",
    "\n",
    "# Display more data in the Jupyter notebook\n",
    "options(repr.matrix.max.cols=500, repr.matrix.max.rows=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>560</li>\n",
       "\t<li>61</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 560\n",
       "\\item 61\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 560\n",
       "2. 61\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 560  61"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A data.frame: 6 × 61</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>X</th><th scope=col>PID</th><th scope=col>gender</th><th scope=col>race</th><th scope=col>dorm</th><th scope=col>life_satisfaction_t1</th><th scope=col>empathy</th><th scope=col>loneliness_t1</th><th scope=col>stress_t1</th><th scope=col>BFI_E</th><th scope=col>BFI_A</th><th scope=col>BFI_C</th><th scope=col>BFI_N</th><th scope=col>BFI_O</th><th scope=col>intl_student</th><th scope=col>family_income</th><th scope=col>life_satisfaction_t2</th><th scope=col>loneliness_t2</th><th scope=col>stress_t2</th><th scope=col>parent_education_highest</th><th scope=col>wellbeing_composite_t1</th><th scope=col>wellbeing_composite_t2</th><th scope=col>degree_in_UNION</th><th scope=col>degree_out_UNION</th><th scope=col>empathy_UNION</th><th scope=col>degree_in_INTIMATE</th><th scope=col>degree_out_INTIMATE</th><th scope=col>empathy_INTIMATE</th><th scope=col>degree_in_ACQUAINTANCE</th><th scope=col>degree_out_ACQUAINTANCE</th><th scope=col>empathy_ACQUAINTANCE</th><th scope=col>degree_in_CloseFrds</th><th scope=col>degree_out_CloseFrds</th><th scope=col>empathy_CloseFrds</th><th scope=col>degree_in_NegEmoSupp</th><th scope=col>degree_out_NegEmoSupp</th><th scope=col>empathy_NegEmoSupp</th><th scope=col>degree_in_PosEmoSupp</th><th scope=col>degree_out_PosEmoSupp</th><th scope=col>empathy_PosEmoSupp</th><th scope=col>degree_in_Responsive</th><th scope=col>degree_out_Responsive</th><th scope=col>empathy_Responsive</th><th scope=col>degree_in_EmpSupp</th><th scope=col>degree_out_EmpSupp</th><th scope=col>empathy_EmpSupp</th><th scope=col>degree_in_PosAff</th><th scope=col>degree_out_PosAff</th><th scope=col>empathy_PosAff</th><th scope=col>degree_in_NegAff</th><th scope=col>degree_out_NegAff</th><th scope=col>empathy_NegAff</th><th scope=col>degree_in_Gossip</th><th scope=col>degree_out_Gossip</th><th scope=col>empathy_Gossip</th><th scope=col>degree_in_Liked</th><th scope=col>degree_out_Liked</th><th scope=col>empathy_Liked</th><th scope=col>degree_in_StudyWith</th><th scope=col>degree_out_StudyWith</th><th scope=col>empathy_StudyWith</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1</th><td>1</td><td>1001</td><td>male  </td><td>south_asian   </td><td>Rinconada</td><td>4.833333</td><td>6.375</td><td>1.333333</td><td>2.5</td><td>6.5</td><td>6.0</td><td>5.5</td><td>3.5</td><td>6.5</td><td>0</td><td> 70000</td><td>6.166667</td><td>2.000000</td><td>1.5</td><td>5</td><td>-0.05862651</td><td> 0.83993983</td><td>3</td><td>0</td><td>      NA</td><td>1</td><td>0</td><td>     NA</td><td>1</td><td>0</td><td>   NA</td><td>1</td><td>0</td><td>     NA</td><td>0</td><td>0</td><td>      NA</td><td>2</td><td>0</td><td>    NA</td><td>0</td><td>0</td><td>    NA</td><td>0</td><td>0</td><td>    NA</td><td>1</td><td>0</td><td>     NA</td><td>0</td><td>0</td><td> NA</td><td>1</td><td>0</td><td>      NA</td><td>1</td><td>0</td><td>   NA</td><td>1</td><td>0</td><td>    NA</td></tr>\n",
       "\t<tr><th scope=row>2</th><td>2</td><td>1047</td><td>female</td><td>other_or_mixed</td><td>Twain    </td><td>5.333333</td><td>6.500</td><td>2.000000</td><td>2.5</td><td>5.5</td><td>6.5</td><td>7.0</td><td>3.0</td><td>6.5</td><td>0</td><td>210000</td><td>5.166667</td><td>2.000000</td><td>3.0</td><td>5</td><td>-0.44690440</td><td>-0.66253028</td><td>6</td><td>4</td><td>6.437500</td><td>4</td><td>4</td><td>6.43750</td><td>0</td><td>1</td><td>6.125</td><td>4</td><td>4</td><td>6.43750</td><td>4</td><td>3</td><td>6.541667</td><td>3</td><td>4</td><td>6.4375</td><td>2</td><td>2</td><td>6.5625</td><td>1</td><td>2</td><td>6.5625</td><td>3</td><td>4</td><td>6.43750</td><td>1</td><td>1</td><td>6.5</td><td>4</td><td>3</td><td>6.541667</td><td>1</td><td>2</td><td>6.000</td><td>2</td><td>1</td><td>6.6250</td></tr>\n",
       "\t<tr><th scope=row>3</th><td>3</td><td>1078</td><td>female</td><td>east_asian    </td><td>Loro     </td><td>5.500000</td><td>6.250</td><td>1.333333</td><td>2.0</td><td>4.5</td><td>6.5</td><td>6.5</td><td>1.5</td><td>6.5</td><td>0</td><td>130000</td><td>5.500000</td><td>2.333333</td><td>3.0</td><td>6</td><td> 0.61446613</td><td>-0.79801599</td><td>1</td><td>0</td><td>      NA</td><td>1</td><td>0</td><td>     NA</td><td>1</td><td>0</td><td>   NA</td><td>1</td><td>0</td><td>     NA</td><td>0</td><td>0</td><td>      NA</td><td>1</td><td>0</td><td>    NA</td><td>1</td><td>0</td><td>    NA</td><td>0</td><td>0</td><td>    NA</td><td>0</td><td>0</td><td>     NA</td><td>0</td><td>1</td><td>5.0</td><td>0</td><td>0</td><td>      NA</td><td>0</td><td>0</td><td>   NA</td><td>0</td><td>0</td><td>    NA</td></tr>\n",
       "\t<tr><th scope=row>4</th><td>4</td><td>1097</td><td>male  </td><td>east_asian    </td><td>Otero    </td><td>6.000000</td><td>5.000</td><td>2.000000</td><td>2.0</td><td>3.0</td><td>4.0</td><td>5.5</td><td>1.5</td><td>4.5</td><td>0</td><td> 90000</td><td>5.833333</td><td>2.000000</td><td>2.5</td><td>6</td><td> 0.22618824</td><td>-0.04126834</td><td>6</td><td>4</td><td>5.812500</td><td>3</td><td>1</td><td>5.62500</td><td>2</td><td>0</td><td>   NA</td><td>2</td><td>1</td><td>5.62500</td><td>1</td><td>1</td><td>5.625000</td><td>1</td><td>1</td><td>6.6250</td><td>0</td><td>1</td><td>5.6250</td><td>0</td><td>1</td><td>4.8750</td><td>1</td><td>1</td><td>6.12500</td><td>0</td><td>0</td><td> NA</td><td>0</td><td>1</td><td>5.625000</td><td>0</td><td>1</td><td>6.000</td><td>3</td><td>1</td><td>6.6250</td></tr>\n",
       "\t<tr><th scope=row>5</th><td>5</td><td>1105</td><td>female</td><td>white         </td><td>Larkin   </td><td>6.666667</td><td>5.750</td><td>2.000000</td><td>2.0</td><td>4.5</td><td>5.0</td><td>5.0</td><td>2.0</td><td>4.5</td><td>0</td><td>170000</td><td>6.666667</td><td>2.000000</td><td>2.0</td><td>4</td><td> 0.48041399</td><td> 0.64021289</td><td>6</td><td>9</td><td>5.847222</td><td>4</td><td>5</td><td>6.02500</td><td>2</td><td>2</td><td>5.875</td><td>3</td><td>4</td><td>5.81250</td><td>2</td><td>3</td><td>6.125000</td><td>2</td><td>2</td><td>5.3750</td><td>2</td><td>2</td><td>6.3125</td><td>1</td><td>4</td><td>6.1875</td><td>2</td><td>1</td><td>6.87500</td><td>1</td><td>0</td><td> NA</td><td>2</td><td>3</td><td>5.750000</td><td>1</td><td>1</td><td>5.125</td><td>4</td><td>2</td><td>6.1875</td></tr>\n",
       "\t<tr><th scope=row>6</th><td>6</td><td>1110</td><td>female</td><td>white         </td><td>Larkin   </td><td>5.166667</td><td>6.750</td><td>2.000000</td><td>2.0</td><td>6.5</td><td>5.0</td><td>6.0</td><td>2.0</td><td>4.5</td><td>0</td><td>110000</td><td>6.833333</td><td>1.666667</td><td>2.0</td><td>5</td><td>-0.09159395</td><td> 0.95635646</td><td>4</td><td>5</td><td>5.550000</td><td>4</td><td>4</td><td>5.40625</td><td>1</td><td>0</td><td>   NA</td><td>3</td><td>4</td><td>5.40625</td><td>3</td><td>4</td><td>5.406250</td><td>3</td><td>2</td><td>6.0625</td><td>2</td><td>2</td><td>5.7500</td><td>3</td><td>1</td><td>6.0000</td><td>2</td><td>4</td><td>5.78125</td><td>0</td><td>0</td><td> NA</td><td>3</td><td>4</td><td>5.406250</td><td>4</td><td>1</td><td>6.000</td><td>3</td><td>4</td><td>5.4375</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 6 × 61\n",
       "\\begin{tabular}{r|lllllllllllllllllllllllllllllllllllllllllllllllllllllllllllll}\n",
       "  & X & PID & gender & race & dorm & life\\_satisfaction\\_t1 & empathy & loneliness\\_t1 & stress\\_t1 & BFI\\_E & BFI\\_A & BFI\\_C & BFI\\_N & BFI\\_O & intl\\_student & family\\_income & life\\_satisfaction\\_t2 & loneliness\\_t2 & stress\\_t2 & parent\\_education\\_highest & wellbeing\\_composite\\_t1 & wellbeing\\_composite\\_t2 & degree\\_in\\_UNION & degree\\_out\\_UNION & empathy\\_UNION & degree\\_in\\_INTIMATE & degree\\_out\\_INTIMATE & empathy\\_INTIMATE & degree\\_in\\_ACQUAINTANCE & degree\\_out\\_ACQUAINTANCE & empathy\\_ACQUAINTANCE & degree\\_in\\_CloseFrds & degree\\_out\\_CloseFrds & empathy\\_CloseFrds & degree\\_in\\_NegEmoSupp & degree\\_out\\_NegEmoSupp & empathy\\_NegEmoSupp & degree\\_in\\_PosEmoSupp & degree\\_out\\_PosEmoSupp & empathy\\_PosEmoSupp & degree\\_in\\_Responsive & degree\\_out\\_Responsive & empathy\\_Responsive & degree\\_in\\_EmpSupp & degree\\_out\\_EmpSupp & empathy\\_EmpSupp & degree\\_in\\_PosAff & degree\\_out\\_PosAff & empathy\\_PosAff & degree\\_in\\_NegAff & degree\\_out\\_NegAff & empathy\\_NegAff & degree\\_in\\_Gossip & degree\\_out\\_Gossip & empathy\\_Gossip & degree\\_in\\_Liked & degree\\_out\\_Liked & empathy\\_Liked & degree\\_in\\_StudyWith & degree\\_out\\_StudyWith & empathy\\_StudyWith\\\\\n",
       "  & <int> & <int> & <fct> & <fct> & <fct> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <int> & <int> & <dbl> & <dbl> & <dbl> & <int> & <dbl> & <dbl> & <int> & <int> & <dbl> & <int> & <int> & <dbl> & <int> & <int> & <dbl> & <int> & <int> & <dbl> & <int> & <int> & <dbl> & <int> & <int> & <dbl> & <int> & <int> & <dbl> & <int> & <int> & <dbl> & <int> & <int> & <dbl> & <int> & <int> & <dbl> & <int> & <int> & <dbl> & <int> & <int> & <dbl> & <int> & <int> & <dbl>\\\\\n",
       "\\hline\n",
       "\t1 & 1 & 1001 & male   & south\\_asian    & Rinconada & 4.833333 & 6.375 & 1.333333 & 2.5 & 6.5 & 6.0 & 5.5 & 3.5 & 6.5 & 0 &  70000 & 6.166667 & 2.000000 & 1.5 & 5 & -0.05862651 &  0.83993983 & 3 & 0 &       NA & 1 & 0 &      NA & 1 & 0 &    NA & 1 & 0 &      NA & 0 & 0 &       NA & 2 & 0 &     NA & 0 & 0 &     NA & 0 & 0 &     NA & 1 & 0 &      NA & 0 & 0 &  NA & 1 & 0 &       NA & 1 & 0 &    NA & 1 & 0 &     NA\\\\\n",
       "\t2 & 2 & 1047 & female & other\\_or\\_mixed & Twain     & 5.333333 & 6.500 & 2.000000 & 2.5 & 5.5 & 6.5 & 7.0 & 3.0 & 6.5 & 0 & 210000 & 5.166667 & 2.000000 & 3.0 & 5 & -0.44690440 & -0.66253028 & 6 & 4 & 6.437500 & 4 & 4 & 6.43750 & 0 & 1 & 6.125 & 4 & 4 & 6.43750 & 4 & 3 & 6.541667 & 3 & 4 & 6.4375 & 2 & 2 & 6.5625 & 1 & 2 & 6.5625 & 3 & 4 & 6.43750 & 1 & 1 & 6.5 & 4 & 3 & 6.541667 & 1 & 2 & 6.000 & 2 & 1 & 6.6250\\\\\n",
       "\t3 & 3 & 1078 & female & east\\_asian     & Loro      & 5.500000 & 6.250 & 1.333333 & 2.0 & 4.5 & 6.5 & 6.5 & 1.5 & 6.5 & 0 & 130000 & 5.500000 & 2.333333 & 3.0 & 6 &  0.61446613 & -0.79801599 & 1 & 0 &       NA & 1 & 0 &      NA & 1 & 0 &    NA & 1 & 0 &      NA & 0 & 0 &       NA & 1 & 0 &     NA & 1 & 0 &     NA & 0 & 0 &     NA & 0 & 0 &      NA & 0 & 1 & 5.0 & 0 & 0 &       NA & 0 & 0 &    NA & 0 & 0 &     NA\\\\\n",
       "\t4 & 4 & 1097 & male   & east\\_asian     & Otero     & 6.000000 & 5.000 & 2.000000 & 2.0 & 3.0 & 4.0 & 5.5 & 1.5 & 4.5 & 0 &  90000 & 5.833333 & 2.000000 & 2.5 & 6 &  0.22618824 & -0.04126834 & 6 & 4 & 5.812500 & 3 & 1 & 5.62500 & 2 & 0 &    NA & 2 & 1 & 5.62500 & 1 & 1 & 5.625000 & 1 & 1 & 6.6250 & 0 & 1 & 5.6250 & 0 & 1 & 4.8750 & 1 & 1 & 6.12500 & 0 & 0 &  NA & 0 & 1 & 5.625000 & 0 & 1 & 6.000 & 3 & 1 & 6.6250\\\\\n",
       "\t5 & 5 & 1105 & female & white          & Larkin    & 6.666667 & 5.750 & 2.000000 & 2.0 & 4.5 & 5.0 & 5.0 & 2.0 & 4.5 & 0 & 170000 & 6.666667 & 2.000000 & 2.0 & 4 &  0.48041399 &  0.64021289 & 6 & 9 & 5.847222 & 4 & 5 & 6.02500 & 2 & 2 & 5.875 & 3 & 4 & 5.81250 & 2 & 3 & 6.125000 & 2 & 2 & 5.3750 & 2 & 2 & 6.3125 & 1 & 4 & 6.1875 & 2 & 1 & 6.87500 & 1 & 0 &  NA & 2 & 3 & 5.750000 & 1 & 1 & 5.125 & 4 & 2 & 6.1875\\\\\n",
       "\t6 & 6 & 1110 & female & white          & Larkin    & 5.166667 & 6.750 & 2.000000 & 2.0 & 6.5 & 5.0 & 6.0 & 2.0 & 4.5 & 0 & 110000 & 6.833333 & 1.666667 & 2.0 & 5 & -0.09159395 &  0.95635646 & 4 & 5 & 5.550000 & 4 & 4 & 5.40625 & 1 & 0 &    NA & 3 & 4 & 5.40625 & 3 & 4 & 5.406250 & 3 & 2 & 6.0625 & 2 & 2 & 5.7500 & 3 & 1 & 6.0000 & 2 & 4 & 5.78125 & 0 & 0 &  NA & 3 & 4 & 5.406250 & 4 & 1 & 6.000 & 3 & 4 & 5.4375\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 6 × 61\n",
       "\n",
       "| <!--/--> | X &lt;int&gt; | PID &lt;int&gt; | gender &lt;fct&gt; | race &lt;fct&gt; | dorm &lt;fct&gt; | life_satisfaction_t1 &lt;dbl&gt; | empathy &lt;dbl&gt; | loneliness_t1 &lt;dbl&gt; | stress_t1 &lt;dbl&gt; | BFI_E &lt;dbl&gt; | BFI_A &lt;dbl&gt; | BFI_C &lt;dbl&gt; | BFI_N &lt;dbl&gt; | BFI_O &lt;dbl&gt; | intl_student &lt;int&gt; | family_income &lt;int&gt; | life_satisfaction_t2 &lt;dbl&gt; | loneliness_t2 &lt;dbl&gt; | stress_t2 &lt;dbl&gt; | parent_education_highest &lt;int&gt; | wellbeing_composite_t1 &lt;dbl&gt; | wellbeing_composite_t2 &lt;dbl&gt; | degree_in_UNION &lt;int&gt; | degree_out_UNION &lt;int&gt; | empathy_UNION &lt;dbl&gt; | degree_in_INTIMATE &lt;int&gt; | degree_out_INTIMATE &lt;int&gt; | empathy_INTIMATE &lt;dbl&gt; | degree_in_ACQUAINTANCE &lt;int&gt; | degree_out_ACQUAINTANCE &lt;int&gt; | empathy_ACQUAINTANCE &lt;dbl&gt; | degree_in_CloseFrds &lt;int&gt; | degree_out_CloseFrds &lt;int&gt; | empathy_CloseFrds &lt;dbl&gt; | degree_in_NegEmoSupp &lt;int&gt; | degree_out_NegEmoSupp &lt;int&gt; | empathy_NegEmoSupp &lt;dbl&gt; | degree_in_PosEmoSupp &lt;int&gt; | degree_out_PosEmoSupp &lt;int&gt; | empathy_PosEmoSupp &lt;dbl&gt; | degree_in_Responsive &lt;int&gt; | degree_out_Responsive &lt;int&gt; | empathy_Responsive &lt;dbl&gt; | degree_in_EmpSupp &lt;int&gt; | degree_out_EmpSupp &lt;int&gt; | empathy_EmpSupp &lt;dbl&gt; | degree_in_PosAff &lt;int&gt; | degree_out_PosAff &lt;int&gt; | empathy_PosAff &lt;dbl&gt; | degree_in_NegAff &lt;int&gt; | degree_out_NegAff &lt;int&gt; | empathy_NegAff &lt;dbl&gt; | degree_in_Gossip &lt;int&gt; | degree_out_Gossip &lt;int&gt; | empathy_Gossip &lt;dbl&gt; | degree_in_Liked &lt;int&gt; | degree_out_Liked &lt;int&gt; | empathy_Liked &lt;dbl&gt; | degree_in_StudyWith &lt;int&gt; | degree_out_StudyWith &lt;int&gt; | empathy_StudyWith &lt;dbl&gt; |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| 1 | 1 | 1001 | male   | south_asian    | Rinconada | 4.833333 | 6.375 | 1.333333 | 2.5 | 6.5 | 6.0 | 5.5 | 3.5 | 6.5 | 0 |  70000 | 6.166667 | 2.000000 | 1.5 | 5 | -0.05862651 |  0.83993983 | 3 | 0 |       NA | 1 | 0 |      NA | 1 | 0 |    NA | 1 | 0 |      NA | 0 | 0 |       NA | 2 | 0 |     NA | 0 | 0 |     NA | 0 | 0 |     NA | 1 | 0 |      NA | 0 | 0 |  NA | 1 | 0 |       NA | 1 | 0 |    NA | 1 | 0 |     NA |\n",
       "| 2 | 2 | 1047 | female | other_or_mixed | Twain     | 5.333333 | 6.500 | 2.000000 | 2.5 | 5.5 | 6.5 | 7.0 | 3.0 | 6.5 | 0 | 210000 | 5.166667 | 2.000000 | 3.0 | 5 | -0.44690440 | -0.66253028 | 6 | 4 | 6.437500 | 4 | 4 | 6.43750 | 0 | 1 | 6.125 | 4 | 4 | 6.43750 | 4 | 3 | 6.541667 | 3 | 4 | 6.4375 | 2 | 2 | 6.5625 | 1 | 2 | 6.5625 | 3 | 4 | 6.43750 | 1 | 1 | 6.5 | 4 | 3 | 6.541667 | 1 | 2 | 6.000 | 2 | 1 | 6.6250 |\n",
       "| 3 | 3 | 1078 | female | east_asian     | Loro      | 5.500000 | 6.250 | 1.333333 | 2.0 | 4.5 | 6.5 | 6.5 | 1.5 | 6.5 | 0 | 130000 | 5.500000 | 2.333333 | 3.0 | 6 |  0.61446613 | -0.79801599 | 1 | 0 |       NA | 1 | 0 |      NA | 1 | 0 |    NA | 1 | 0 |      NA | 0 | 0 |       NA | 1 | 0 |     NA | 1 | 0 |     NA | 0 | 0 |     NA | 0 | 0 |      NA | 0 | 1 | 5.0 | 0 | 0 |       NA | 0 | 0 |    NA | 0 | 0 |     NA |\n",
       "| 4 | 4 | 1097 | male   | east_asian     | Otero     | 6.000000 | 5.000 | 2.000000 | 2.0 | 3.0 | 4.0 | 5.5 | 1.5 | 4.5 | 0 |  90000 | 5.833333 | 2.000000 | 2.5 | 6 |  0.22618824 | -0.04126834 | 6 | 4 | 5.812500 | 3 | 1 | 5.62500 | 2 | 0 |    NA | 2 | 1 | 5.62500 | 1 | 1 | 5.625000 | 1 | 1 | 6.6250 | 0 | 1 | 5.6250 | 0 | 1 | 4.8750 | 1 | 1 | 6.12500 | 0 | 0 |  NA | 0 | 1 | 5.625000 | 0 | 1 | 6.000 | 3 | 1 | 6.6250 |\n",
       "| 5 | 5 | 1105 | female | white          | Larkin    | 6.666667 | 5.750 | 2.000000 | 2.0 | 4.5 | 5.0 | 5.0 | 2.0 | 4.5 | 0 | 170000 | 6.666667 | 2.000000 | 2.0 | 4 |  0.48041399 |  0.64021289 | 6 | 9 | 5.847222 | 4 | 5 | 6.02500 | 2 | 2 | 5.875 | 3 | 4 | 5.81250 | 2 | 3 | 6.125000 | 2 | 2 | 5.3750 | 2 | 2 | 6.3125 | 1 | 4 | 6.1875 | 2 | 1 | 6.87500 | 1 | 0 |  NA | 2 | 3 | 5.750000 | 1 | 1 | 5.125 | 4 | 2 | 6.1875 |\n",
       "| 6 | 6 | 1110 | female | white          | Larkin    | 5.166667 | 6.750 | 2.000000 | 2.0 | 6.5 | 5.0 | 6.0 | 2.0 | 4.5 | 0 | 110000 | 6.833333 | 1.666667 | 2.0 | 5 | -0.09159395 |  0.95635646 | 4 | 5 | 5.550000 | 4 | 4 | 5.40625 | 1 | 0 |    NA | 3 | 4 | 5.40625 | 3 | 4 | 5.406250 | 3 | 2 | 6.0625 | 2 | 2 | 5.7500 | 3 | 1 | 6.0000 | 2 | 4 | 5.78125 | 0 | 0 |  NA | 3 | 4 | 5.406250 | 4 | 1 | 6.000 | 3 | 4 | 5.4375 |\n",
       "\n"
      ],
      "text/plain": [
       "  X PID  gender race           dorm      life_satisfaction_t1 empathy\n",
       "1 1 1001 male   south_asian    Rinconada 4.833333             6.375  \n",
       "2 2 1047 female other_or_mixed Twain     5.333333             6.500  \n",
       "3 3 1078 female east_asian     Loro      5.500000             6.250  \n",
       "4 4 1097 male   east_asian     Otero     6.000000             5.000  \n",
       "5 5 1105 female white          Larkin    6.666667             5.750  \n",
       "6 6 1110 female white          Larkin    5.166667             6.750  \n",
       "  loneliness_t1 stress_t1 BFI_E BFI_A BFI_C BFI_N BFI_O intl_student\n",
       "1 1.333333      2.5       6.5   6.0   5.5   3.5   6.5   0           \n",
       "2 2.000000      2.5       5.5   6.5   7.0   3.0   6.5   0           \n",
       "3 1.333333      2.0       4.5   6.5   6.5   1.5   6.5   0           \n",
       "4 2.000000      2.0       3.0   4.0   5.5   1.5   4.5   0           \n",
       "5 2.000000      2.0       4.5   5.0   5.0   2.0   4.5   0           \n",
       "6 2.000000      2.0       6.5   5.0   6.0   2.0   4.5   0           \n",
       "  family_income life_satisfaction_t2 loneliness_t2 stress_t2\n",
       "1  70000        6.166667             2.000000      1.5      \n",
       "2 210000        5.166667             2.000000      3.0      \n",
       "3 130000        5.500000             2.333333      3.0      \n",
       "4  90000        5.833333             2.000000      2.5      \n",
       "5 170000        6.666667             2.000000      2.0      \n",
       "6 110000        6.833333             1.666667      2.0      \n",
       "  parent_education_highest wellbeing_composite_t1 wellbeing_composite_t2\n",
       "1 5                        -0.05862651             0.83993983           \n",
       "2 5                        -0.44690440            -0.66253028           \n",
       "3 6                         0.61446613            -0.79801599           \n",
       "4 6                         0.22618824            -0.04126834           \n",
       "5 4                         0.48041399             0.64021289           \n",
       "6 5                        -0.09159395             0.95635646           \n",
       "  degree_in_UNION degree_out_UNION empathy_UNION degree_in_INTIMATE\n",
       "1 3               0                      NA      1                 \n",
       "2 6               4                6.437500      4                 \n",
       "3 1               0                      NA      1                 \n",
       "4 6               4                5.812500      3                 \n",
       "5 6               9                5.847222      4                 \n",
       "6 4               5                5.550000      4                 \n",
       "  degree_out_INTIMATE empathy_INTIMATE degree_in_ACQUAINTANCE\n",
       "1 0                        NA          1                     \n",
       "2 4                   6.43750          0                     \n",
       "3 0                        NA          1                     \n",
       "4 1                   5.62500          2                     \n",
       "5 5                   6.02500          2                     \n",
       "6 4                   5.40625          1                     \n",
       "  degree_out_ACQUAINTANCE empathy_ACQUAINTANCE degree_in_CloseFrds\n",
       "1 0                          NA                1                  \n",
       "2 1                       6.125                4                  \n",
       "3 0                          NA                1                  \n",
       "4 0                          NA                2                  \n",
       "5 2                       5.875                3                  \n",
       "6 0                          NA                3                  \n",
       "  degree_out_CloseFrds empathy_CloseFrds degree_in_NegEmoSupp\n",
       "1 0                         NA           0                   \n",
       "2 4                    6.43750           4                   \n",
       "3 0                         NA           0                   \n",
       "4 1                    5.62500           1                   \n",
       "5 4                    5.81250           2                   \n",
       "6 4                    5.40625           3                   \n",
       "  degree_out_NegEmoSupp empathy_NegEmoSupp degree_in_PosEmoSupp\n",
       "1 0                           NA           2                   \n",
       "2 3                     6.541667           3                   \n",
       "3 0                           NA           1                   \n",
       "4 1                     5.625000           1                   \n",
       "5 3                     6.125000           2                   \n",
       "6 4                     5.406250           3                   \n",
       "  degree_out_PosEmoSupp empathy_PosEmoSupp degree_in_Responsive\n",
       "1 0                         NA             0                   \n",
       "2 4                     6.4375             2                   \n",
       "3 0                         NA             1                   \n",
       "4 1                     6.6250             0                   \n",
       "5 2                     5.3750             2                   \n",
       "6 2                     6.0625             2                   \n",
       "  degree_out_Responsive empathy_Responsive degree_in_EmpSupp degree_out_EmpSupp\n",
       "1 0                         NA             0                 0                 \n",
       "2 2                     6.5625             1                 2                 \n",
       "3 0                         NA             0                 0                 \n",
       "4 1                     5.6250             0                 1                 \n",
       "5 2                     6.3125             1                 4                 \n",
       "6 2                     5.7500             3                 1                 \n",
       "  empathy_EmpSupp degree_in_PosAff degree_out_PosAff empathy_PosAff\n",
       "1     NA          1                0                      NA       \n",
       "2 6.5625          3                4                 6.43750       \n",
       "3     NA          0                0                      NA       \n",
       "4 4.8750          1                1                 6.12500       \n",
       "5 6.1875          2                1                 6.87500       \n",
       "6 6.0000          2                4                 5.78125       \n",
       "  degree_in_NegAff degree_out_NegAff empathy_NegAff degree_in_Gossip\n",
       "1 0                0                  NA            1               \n",
       "2 1                1                 6.5            4               \n",
       "3 0                1                 5.0            0               \n",
       "4 0                0                  NA            0               \n",
       "5 1                0                  NA            2               \n",
       "6 0                0                  NA            3               \n",
       "  degree_out_Gossip empathy_Gossip degree_in_Liked degree_out_Liked\n",
       "1 0                       NA       1               0               \n",
       "2 3                 6.541667       1               2               \n",
       "3 0                       NA       0               0               \n",
       "4 1                 5.625000       0               1               \n",
       "5 3                 5.750000       1               1               \n",
       "6 4                 5.406250       4               1               \n",
       "  empathy_Liked degree_in_StudyWith degree_out_StudyWith empathy_StudyWith\n",
       "1    NA         1                   0                        NA           \n",
       "2 6.000         2                   1                    6.6250           \n",
       "3    NA         0                   0                        NA           \n",
       "4 6.000         3                   1                    6.6250           \n",
       "5 5.125         4                   2                    6.1875           \n",
       "6 6.000         3                   4                    5.4375           "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = read.csv(DATA_FILE, na.strings=c(\"\", \" \", \"NA\"))\n",
    "dim(df)\n",
    "head(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A matrix: 2 × 4 of type dbl</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>Estimate</th><th scope=col>Std. Error</th><th scope=col>t value</th><th scope=col>Pr(&gt;|t|)</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>(Intercept)</th><td>1.0228226</td><td>0.15714766</td><td> 6.508672</td><td>1.692618e-10</td></tr>\n",
       "\t<tr><th scope=row>life_satisfaction_t1</th><td>0.7655304</td><td>0.03037431</td><td>25.203219</td><td>4.188638e-94</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A matrix: 2 × 4 of type dbl\n",
       "\\begin{tabular}{r|llll}\n",
       "  & Estimate & Std. Error & t value & Pr(>\\textbar{}t\\textbar{})\\\\\n",
       "\\hline\n",
       "\t(Intercept) & 1.0228226 & 0.15714766 &  6.508672 & 1.692618e-10\\\\\n",
       "\tlife\\_satisfaction\\_t1 & 0.7655304 & 0.03037431 & 25.203219 & 4.188638e-94\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A matrix: 2 × 4 of type dbl\n",
       "\n",
       "| <!--/--> | Estimate | Std. Error | t value | Pr(&gt;|t|) |\n",
       "|---|---|---|---|---|\n",
       "| (Intercept) | 1.0228226 | 0.15714766 |  6.508672 | 1.692618e-10 |\n",
       "| life_satisfaction_t1 | 0.7655304 | 0.03037431 | 25.203219 | 4.188638e-94 |\n",
       "\n"
      ],
      "text/plain": [
       "                     Estimate  Std. Error t value   Pr(>|t|)    \n",
       "(Intercept)          1.0228226 0.15714766  6.508672 1.692618e-10\n",
       "life_satisfaction_t1 0.7655304 0.03037431 25.203219 4.188638e-94"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_C = lm(life_satisfaction_t2 ~ life_satisfaction_t1, df)\n",
    "summary(model_C)$coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A data.frame: 26 × 4</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>column</th><th scope=col>beta</th><th scope=col>p</th><th scope=col>p_adjusted</th></tr>\n",
       "\t<tr><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>degree_in_UNION        </td><td> 0.03491602</td><td>0.049697962</td><td>0.8448654</td></tr>\n",
       "\t<tr><td>degree_out_UNION       </td><td> 0.03826154</td><td>0.097791212</td><td>1.0000000</td></tr>\n",
       "\t<tr><td>degree_in_INTIMATE     </td><td> 0.05057935</td><td>0.038389709</td><td>0.7677942</td></tr>\n",
       "\t<tr><td>degree_out_INTIMATE    </td><td> 0.05591758</td><td>0.102163446</td><td>1.0000000</td></tr>\n",
       "\t<tr><td>degree_in_ACQUAINTANCE </td><td> 0.04012626</td><td>0.354450633</td><td>1.0000000</td></tr>\n",
       "\t<tr><td>degree_out_ACQUAINTANCE</td><td>-0.04196406</td><td>0.429243249</td><td>1.0000000</td></tr>\n",
       "\t<tr><td>degree_in_CloseFrds    </td><td> 0.05763047</td><td>0.031686587</td><td>0.6654183</td></tr>\n",
       "\t<tr><td>degree_out_CloseFrds   </td><td> 0.03760797</td><td>0.311505237</td><td>1.0000000</td></tr>\n",
       "\t<tr><td>degree_in_NegEmoSupp   </td><td> 0.06589729</td><td>0.041066762</td><td>0.7677942</td></tr>\n",
       "\t<tr><td>degree_out_NegEmoSupp  </td><td> 0.09727931</td><td>0.013384346</td><td>0.3078399</td></tr>\n",
       "\t<tr><td>degree_in_PosEmoSupp   </td><td> 0.06588546</td><td>0.058686832</td><td>0.9389893</td></tr>\n",
       "\t<tr><td>degree_out_PosEmoSupp  </td><td> 0.04196443</td><td>0.296086214</td><td>1.0000000</td></tr>\n",
       "\t<tr><td>degree_in_Responsive   </td><td> 0.07193594</td><td>0.038802439</td><td>0.7677942</td></tr>\n",
       "\t<tr><td>degree_out_Responsive  </td><td> 0.11203087</td><td>0.008611669</td><td>0.2152917</td></tr>\n",
       "\t<tr><td>degree_in_EmpSupp      </td><td> 0.03698861</td><td>0.293133420</td><td>1.0000000</td></tr>\n",
       "\t<tr><td>degree_out_EmpSupp     </td><td> 0.01991670</td><td>0.693331604</td><td>1.0000000</td></tr>\n",
       "\t<tr><td>degree_in_PosAff       </td><td> 0.08764350</td><td>0.004715976</td><td>0.1226154</td></tr>\n",
       "\t<tr><td>degree_out_PosAff      </td><td> 0.06392774</td><td>0.126618925</td><td>1.0000000</td></tr>\n",
       "\t<tr><td>degree_in_NegAff       </td><td>-0.06876727</td><td>0.211343990</td><td>1.0000000</td></tr>\n",
       "\t<tr><td>degree_out_NegAff      </td><td>-0.07850644</td><td>0.320531817</td><td>1.0000000</td></tr>\n",
       "\t<tr><td>degree_in_Gossip       </td><td> 0.01781685</td><td>0.635851758</td><td>1.0000000</td></tr>\n",
       "\t<tr><td>degree_out_Gossip      </td><td> 0.04864694</td><td>0.252763344</td><td>1.0000000</td></tr>\n",
       "\t<tr><td>degree_in_Liked        </td><td> 0.06663928</td><td>0.010848711</td><td>0.2603691</td></tr>\n",
       "\t<tr><td>degree_out_Liked       </td><td> 0.06205682</td><td>0.194162819</td><td>1.0000000</td></tr>\n",
       "\t<tr><td>degree_in_StudyWith    </td><td> 0.08822830</td><td>0.015082835</td><td>0.3318224</td></tr>\n",
       "\t<tr><td>degree_out_StudyWith   </td><td> 0.07335656</td><td>0.089030906</td><td>1.0000000</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 26 × 4\n",
       "\\begin{tabular}{llll}\n",
       " column & beta & p & p\\_adjusted\\\\\n",
       " <fct> & <dbl> & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t degree\\_in\\_UNION         &  0.03491602 & 0.049697962 & 0.8448654\\\\\n",
       "\t degree\\_out\\_UNION        &  0.03826154 & 0.097791212 & 1.0000000\\\\\n",
       "\t degree\\_in\\_INTIMATE      &  0.05057935 & 0.038389709 & 0.7677942\\\\\n",
       "\t degree\\_out\\_INTIMATE     &  0.05591758 & 0.102163446 & 1.0000000\\\\\n",
       "\t degree\\_in\\_ACQUAINTANCE  &  0.04012626 & 0.354450633 & 1.0000000\\\\\n",
       "\t degree\\_out\\_ACQUAINTANCE & -0.04196406 & 0.429243249 & 1.0000000\\\\\n",
       "\t degree\\_in\\_CloseFrds     &  0.05763047 & 0.031686587 & 0.6654183\\\\\n",
       "\t degree\\_out\\_CloseFrds    &  0.03760797 & 0.311505237 & 1.0000000\\\\\n",
       "\t degree\\_in\\_NegEmoSupp    &  0.06589729 & 0.041066762 & 0.7677942\\\\\n",
       "\t degree\\_out\\_NegEmoSupp   &  0.09727931 & 0.013384346 & 0.3078399\\\\\n",
       "\t degree\\_in\\_PosEmoSupp    &  0.06588546 & 0.058686832 & 0.9389893\\\\\n",
       "\t degree\\_out\\_PosEmoSupp   &  0.04196443 & 0.296086214 & 1.0000000\\\\\n",
       "\t degree\\_in\\_Responsive    &  0.07193594 & 0.038802439 & 0.7677942\\\\\n",
       "\t degree\\_out\\_Responsive   &  0.11203087 & 0.008611669 & 0.2152917\\\\\n",
       "\t degree\\_in\\_EmpSupp       &  0.03698861 & 0.293133420 & 1.0000000\\\\\n",
       "\t degree\\_out\\_EmpSupp      &  0.01991670 & 0.693331604 & 1.0000000\\\\\n",
       "\t degree\\_in\\_PosAff        &  0.08764350 & 0.004715976 & 0.1226154\\\\\n",
       "\t degree\\_out\\_PosAff       &  0.06392774 & 0.126618925 & 1.0000000\\\\\n",
       "\t degree\\_in\\_NegAff        & -0.06876727 & 0.211343990 & 1.0000000\\\\\n",
       "\t degree\\_out\\_NegAff       & -0.07850644 & 0.320531817 & 1.0000000\\\\\n",
       "\t degree\\_in\\_Gossip        &  0.01781685 & 0.635851758 & 1.0000000\\\\\n",
       "\t degree\\_out\\_Gossip       &  0.04864694 & 0.252763344 & 1.0000000\\\\\n",
       "\t degree\\_in\\_Liked         &  0.06663928 & 0.010848711 & 0.2603691\\\\\n",
       "\t degree\\_out\\_Liked        &  0.06205682 & 0.194162819 & 1.0000000\\\\\n",
       "\t degree\\_in\\_StudyWith     &  0.08822830 & 0.015082835 & 0.3318224\\\\\n",
       "\t degree\\_out\\_StudyWith    &  0.07335656 & 0.089030906 & 1.0000000\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 26 × 4\n",
       "\n",
       "| column &lt;fct&gt; | beta &lt;dbl&gt; | p &lt;dbl&gt; | p_adjusted &lt;dbl&gt; |\n",
       "|---|---|---|---|\n",
       "| degree_in_UNION         |  0.03491602 | 0.049697962 | 0.8448654 |\n",
       "| degree_out_UNION        |  0.03826154 | 0.097791212 | 1.0000000 |\n",
       "| degree_in_INTIMATE      |  0.05057935 | 0.038389709 | 0.7677942 |\n",
       "| degree_out_INTIMATE     |  0.05591758 | 0.102163446 | 1.0000000 |\n",
       "| degree_in_ACQUAINTANCE  |  0.04012626 | 0.354450633 | 1.0000000 |\n",
       "| degree_out_ACQUAINTANCE | -0.04196406 | 0.429243249 | 1.0000000 |\n",
       "| degree_in_CloseFrds     |  0.05763047 | 0.031686587 | 0.6654183 |\n",
       "| degree_out_CloseFrds    |  0.03760797 | 0.311505237 | 1.0000000 |\n",
       "| degree_in_NegEmoSupp    |  0.06589729 | 0.041066762 | 0.7677942 |\n",
       "| degree_out_NegEmoSupp   |  0.09727931 | 0.013384346 | 0.3078399 |\n",
       "| degree_in_PosEmoSupp    |  0.06588546 | 0.058686832 | 0.9389893 |\n",
       "| degree_out_PosEmoSupp   |  0.04196443 | 0.296086214 | 1.0000000 |\n",
       "| degree_in_Responsive    |  0.07193594 | 0.038802439 | 0.7677942 |\n",
       "| degree_out_Responsive   |  0.11203087 | 0.008611669 | 0.2152917 |\n",
       "| degree_in_EmpSupp       |  0.03698861 | 0.293133420 | 1.0000000 |\n",
       "| degree_out_EmpSupp      |  0.01991670 | 0.693331604 | 1.0000000 |\n",
       "| degree_in_PosAff        |  0.08764350 | 0.004715976 | 0.1226154 |\n",
       "| degree_out_PosAff       |  0.06392774 | 0.126618925 | 1.0000000 |\n",
       "| degree_in_NegAff        | -0.06876727 | 0.211343990 | 1.0000000 |\n",
       "| degree_out_NegAff       | -0.07850644 | 0.320531817 | 1.0000000 |\n",
       "| degree_in_Gossip        |  0.01781685 | 0.635851758 | 1.0000000 |\n",
       "| degree_out_Gossip       |  0.04864694 | 0.252763344 | 1.0000000 |\n",
       "| degree_in_Liked         |  0.06663928 | 0.010848711 | 0.2603691 |\n",
       "| degree_out_Liked        |  0.06205682 | 0.194162819 | 1.0000000 |\n",
       "| degree_in_StudyWith     |  0.08822830 | 0.015082835 | 0.3318224 |\n",
       "| degree_out_StudyWith    |  0.07335656 | 0.089030906 | 1.0000000 |\n",
       "\n"
      ],
      "text/plain": [
       "   column                  beta        p           p_adjusted\n",
       "1  degree_in_UNION          0.03491602 0.049697962 0.8448654 \n",
       "2  degree_out_UNION         0.03826154 0.097791212 1.0000000 \n",
       "3  degree_in_INTIMATE       0.05057935 0.038389709 0.7677942 \n",
       "4  degree_out_INTIMATE      0.05591758 0.102163446 1.0000000 \n",
       "5  degree_in_ACQUAINTANCE   0.04012626 0.354450633 1.0000000 \n",
       "6  degree_out_ACQUAINTANCE -0.04196406 0.429243249 1.0000000 \n",
       "7  degree_in_CloseFrds      0.05763047 0.031686587 0.6654183 \n",
       "8  degree_out_CloseFrds     0.03760797 0.311505237 1.0000000 \n",
       "9  degree_in_NegEmoSupp     0.06589729 0.041066762 0.7677942 \n",
       "10 degree_out_NegEmoSupp    0.09727931 0.013384346 0.3078399 \n",
       "11 degree_in_PosEmoSupp     0.06588546 0.058686832 0.9389893 \n",
       "12 degree_out_PosEmoSupp    0.04196443 0.296086214 1.0000000 \n",
       "13 degree_in_Responsive     0.07193594 0.038802439 0.7677942 \n",
       "14 degree_out_Responsive    0.11203087 0.008611669 0.2152917 \n",
       "15 degree_in_EmpSupp        0.03698861 0.293133420 1.0000000 \n",
       "16 degree_out_EmpSupp       0.01991670 0.693331604 1.0000000 \n",
       "17 degree_in_PosAff         0.08764350 0.004715976 0.1226154 \n",
       "18 degree_out_PosAff        0.06392774 0.126618925 1.0000000 \n",
       "19 degree_in_NegAff        -0.06876727 0.211343990 1.0000000 \n",
       "20 degree_out_NegAff       -0.07850644 0.320531817 1.0000000 \n",
       "21 degree_in_Gossip         0.01781685 0.635851758 1.0000000 \n",
       "22 degree_out_Gossip        0.04864694 0.252763344 1.0000000 \n",
       "23 degree_in_Liked          0.06663928 0.010848711 0.2603691 \n",
       "24 degree_out_Liked         0.06205682 0.194162819 1.0000000 \n",
       "25 degree_in_StudyWith      0.08822830 0.015082835 0.3318224 \n",
       "26 degree_out_StudyWith     0.07335656 0.089030906 1.0000000 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "frame = NULL\n",
    "for (col in names(df)) {\n",
    "    if (startsWith(col, 'degree')) {\n",
    "        model = lm(as.formula(paste('life_satisfaction_t2 ~', col)), df)\n",
    "        b = summary(model)$coefficients[2, 1]\n",
    "        p = summary(model)$coefficients[2, 4]\n",
    "        frame = rbind(frame, c(col, b, p))\n",
    "    }\n",
    "}\n",
    "frame = as.data.frame(frame)\n",
    "names(frame) = c('column', 'beta', 'p')\n",
    "frame$beta = as.numeric(as.character(frame$beta))\n",
    "frame$p = as.numeric(as.character(frame$p))\n",
    "frame$p_adjusted = p.adjust(frame$p, method=\"holm\")\n",
    "frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "r-3.6.2"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
